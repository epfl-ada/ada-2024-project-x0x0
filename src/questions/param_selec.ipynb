{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this file will make a csv file called pca_transformed_data.csv which will contain the new features to use for K means clustering (which explain 95% of the variance- but we can change this accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enzo sent me the directly preprocessed file because I don't have enough storage right now\n",
    "#But you can just run the pipeline otherwise\n",
    "df = pd.read_csv('../../knnData/BA_US_knn_text.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>user_id</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>avg</th>\n",
       "      <th>user_state</th>\n",
       "      <th>beer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kupfer Kolsch</td>\n",
       "      <td>289320.0</td>\n",
       "      <td>Copper State Brewing Company</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>Kölsch</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.76</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Northwestern Alt</td>\n",
       "      <td>289321.0</td>\n",
       "      <td>Copper State Brewing Company</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>4.6</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.58</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Cent Wheat</td>\n",
       "      <td>289319.0</td>\n",
       "      <td>Copper State Brewing Company</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>Witbier</td>\n",
       "      <td>5.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beer_name   beer_id                  brewery_name  brewery_id  \\\n",
       "0     Kupfer Kolsch  289320.0  Copper State Brewing Company     49595.0   \n",
       "1  Northwestern Alt  289321.0  Copper State Brewing Company     49595.0   \n",
       "2    One Cent Wheat  289319.0  Copper State Brewing Company     49595.0   \n",
       "\n",
       "     style  abv       user_id  appearance  aroma  palate  taste  overall  \\\n",
       "0   Kölsch  4.4  n2185.211743        2.50   4.00    4.00   3.75     3.75   \n",
       "1  Altbier  4.6  n2185.211743        3.00   3.75    4.00   3.50     3.50   \n",
       "2  Witbier  5.4  n2185.211743        3.75   3.25    3.75   3.50     3.50   \n",
       "\n",
       "   rating text   avg      user_state beer_state  \n",
       "0    3.76  NaN  3.76  North Carolina  Wisconsin  \n",
       "1    3.58  NaN  3.58  North Carolina  Wisconsin  \n",
       "2    3.48  NaN  3.48  North Carolina  Wisconsin  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>user_id</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49595.0</td>\n",
       "      <td>Kölsch</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49595.0</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>4.6</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49595.0</td>\n",
       "      <td>Witbier</td>\n",
       "      <td>5.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brewery_id    style  abv       user_id  appearance  aroma  palate  taste  \\\n",
       "0     49595.0   Kölsch  4.4  n2185.211743        2.50   4.00    4.00   3.75   \n",
       "1     49595.0  Altbier  4.6  n2185.211743        3.00   3.75    4.00   3.50   \n",
       "2     49595.0  Witbier  5.4  n2185.211743        3.75   3.25    3.75   3.50   \n",
       "\n",
       "   overall  rating  \n",
       "0     3.75    3.76  \n",
       "1     3.50    3.58  \n",
       "2     3.50    3.48  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['beer_name', 'beer_id','brewery_name','avg','user_state', 'beer_state', 'text']\n",
    "\n",
    "# Drop the specified columns\n",
    "X = df.drop(columns=columns_to_drop)\n",
    "y = df['user_state']\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abv</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>style_Altbier</th>\n",
       "      <th>style_American Adjunct Lager</th>\n",
       "      <th>style_American Amber / Red Ale</th>\n",
       "      <th>...</th>\n",
       "      <th>style_Scottish Gruit / Ancient Herbed Ale</th>\n",
       "      <th>style_Smoked Beer</th>\n",
       "      <th>style_Tripel</th>\n",
       "      <th>style_Vienna Lager</th>\n",
       "      <th>style_Weizenbock</th>\n",
       "      <th>style_Wheatwine</th>\n",
       "      <th>style_Winter Warmer</th>\n",
       "      <th>style_Witbier</th>\n",
       "      <th>user_id_encoded</th>\n",
       "      <th>brewery_id_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.58</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abv  appearance  aroma  palate  taste  overall  rating  style_Altbier  \\\n",
       "0  4.4        2.50   4.00    4.00   3.75     3.75    3.76          False   \n",
       "1  4.6        3.00   3.75    4.00   3.50     3.50    3.58           True   \n",
       "2  5.4        3.75   3.25    3.75   3.50     3.50    3.48          False   \n",
       "\n",
       "   style_American Adjunct Lager  style_American Amber / Red Ale  ...  \\\n",
       "0                         False                           False  ...   \n",
       "1                         False                           False  ...   \n",
       "2                         False                           False  ...   \n",
       "\n",
       "   style_Scottish Gruit / Ancient Herbed Ale  style_Smoked Beer  style_Tripel  \\\n",
       "0                                      False              False         False   \n",
       "1                                      False              False         False   \n",
       "2                                      False              False         False   \n",
       "\n",
       "   style_Vienna Lager  style_Weizenbock  style_Wheatwine  style_Winter Warmer  \\\n",
       "0               False             False            False                False   \n",
       "1               False             False            False                False   \n",
       "2               False             False            False                False   \n",
       "\n",
       "   style_Witbier  user_id_encoded  brewery_id_encoded  \n",
       "0          False          0.00036            0.000001  \n",
       "1          False          0.00036            0.000001  \n",
       "2           True          0.00036            0.000001  \n",
       "\n",
       "[3 rows x 112 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#one hot encode beer style\n",
    "#frequency encode brewery_id and user_id\n",
    "\n",
    "X = pd.get_dummies(X, columns=['style'], prefix=['style'])\n",
    "user_frequency = X['user_id'].value_counts() / len(X)  # Frequency of each user_id\n",
    "\n",
    "# Map each user_id to its frequency\n",
    "X['user_id_encoded'] = X['user_id'].map(user_frequency)\n",
    "brewery_frequency = X['brewery_id'].value_counts() / len(X)  # Frequency of each brewery_id\n",
    "\n",
    "# Map each brewery_id to its frequency\n",
    "X['brewery_id_encoded'] = X['brewery_id'].map(brewery_frequency)\n",
    "X = X.drop(columns=['user_id', 'brewery_id'])\n",
    "\n",
    "#label encoding target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "X.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Assuming your DataFrame is named 'X' and the target variable is 'y' (already defined)\\n\\n# Initialize the RandomForestClassifier\\nrf = RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42)  # Limit the depth of each tree\\nrf.fit(X, y)\\n\\n# Fit the model on the data\\nrf.fit(X, y)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# Assuming your DataFrame is named 'X' and the target variable is 'y' (already defined)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42)  # Limit the depth of each tree\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Fit the model on the data\n",
    "rf.fit(X, y)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Get feature importances from the trained model\\nfeature_importances = rf.feature_importances_\\n\\nfeature_names = X.columns\\n\\nfeature_importance_df = pd.DataFrame({\\n    'Feature': feature_names,\\n    'Importance': feature_importances\\n})\\n\\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\\n\\n# Print the feature rankings\\n\\nfeature_importance_df.head(15)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Get feature importances from the trained model\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature rankings\n",
    "\n",
    "feature_importance_df.head(15)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Plot the feature importances\\nplt.figure(figsize=(12, 8))\\nplt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\\nplt.xlabel('Feature Importance')\\nplt.ylabel('Feature')\\nplt.title('Feature Importance Ranking')\\nplt.gca().invert_yaxis()\\nplt.show(\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance Ranking')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show('''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covariance matrix to remove highly correlated variables first\n",
    "#PCA to reduce feature dimension\n",
    "\n",
    "corr_matrix = X.corr()  # Compute correlation matrix for your features\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with more than a 0.8 correlation value\n",
      "  Feature1 Feature2  Correlation\n",
      "0    aroma   rating     0.883635\n",
      "1   palate   rating     0.858498\n",
      "2    taste  overall     0.878233\n",
      "3    taste   rating     0.963339\n",
      "4  overall   rating     0.931130\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.8\n",
    "# Extract the upper triangle of the correlation matrix (excluding diagonal)\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find all feature pairs with correlation above the threshold\n",
    "high_corr_pairs = []\n",
    "for i in range(len(upper_triangle.columns)):\n",
    "    for j in range(i + 1, len(upper_triangle.columns)):\n",
    "        if abs(upper_triangle.iloc[i, j]) > threshold:  # Check threshold\n",
    "            high_corr_pairs.append(\n",
    "                (upper_triangle.index[i], upper_triangle.columns[j], upper_triangle.iloc[i, j])\n",
    "            )\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "high_corr_df = pd.DataFrame(high_corr_pairs, columns=[\"Feature1\", \"Feature2\", \"Correlation\"])\n",
    "print(\"Features with more than a 0.8 correlation value\")\n",
    "print(high_corr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually removing features: Remove aroma (since rating is central and likely more informative).\n",
    "Remove palate (same reasoning).\n",
    "Remove overall (keep taste or vice versa). (for now lets keep overall and remove taste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = ['aroma', 'palate', 'overall']\n",
    "X = X.drop(columns=features_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.14 GiB for an array with shape (6331638, 109) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m iter_imputer \u001b[38;5;241m=\u001b[39m IterativeImputer(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m X_iter_imputed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43miter_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_iter_imputed\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#scaler = StandardScaler()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:743\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_sequence_ \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_imputer_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 743\u001b[0m X, Xt, mask_missing_values, complete_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_imputation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit_indicator(complete_mask)\n\u001b[0;32m    748\u001b[0m X_indicator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_transform_indicator(complete_mask)\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:636\u001b[0m, in \u001b[0;36mIterativeImputer._initial_imputation\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_imputer_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_imputer_ \u001b[38;5;241m=\u001b[39m SimpleImputer(\n\u001b[0;32m    631\u001b[0m         missing_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values,\n\u001b[0;32m    632\u001b[0m         strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_strategy,\n\u001b[0;32m    633\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value,\n\u001b[0;32m    634\u001b[0m         keep_empty_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_empty_features,\n\u001b[0;32m    635\u001b[0m     )\u001b[38;5;241m.\u001b[39mset_output(transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 636\u001b[0m     X_filled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_imputer_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    638\u001b[0m     X_filled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_imputer_\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\impute\\_base.py:438\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_fit(\n\u001b[0;32m    435\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values, fill_value\n\u001b[0;32m    436\u001b[0m     )\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dense_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\impute\\_base.py:498\u001b[0m, in \u001b[0;36mSimpleImputer._dense_fit\u001b[1;34m(self, X, strategy, missing_values, fill_value)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# Mean\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 498\u001b[0m     mean_masked \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# Avoid the warning \"Warning: converting a masked element to nan.\"\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mgetdata(mean_masked)\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\numpy\\ma\\core.py:6882\u001b[0m, in \u001b[0;36m_frommethod.__call__\u001b[1;34m(self, a, *args, **params)\u001b[0m\n\u001b[0;32m   6878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6879\u001b[0m     \u001b[38;5;66;03m# use the corresponding np function\u001b[39;00m\n\u001b[0;32m   6880\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(np, method_name)\n\u001b[1;32m-> 6882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\numpy\\ma\\core.py:5343\u001b[0m, in \u001b[0;36mMaskedArray.mean\u001b[1;34m(self, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   5341\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   5342\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 5343\u001b[0m dsum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5344\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount(axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   5345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cnt\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m () \u001b[38;5;129;01mand\u001b[39;00m (cnt \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\numpy\\ma\\core.py:5175\u001b[0m, in \u001b[0;36mMaskedArray.sum\u001b[1;34m(self, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   5173\u001b[0m \u001b[38;5;66;03m# No explicit output\u001b[39;00m\n\u001b[0;32m   5174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 5175\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilled\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   5176\u001b[0m     rndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   5177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rndim:\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\numpy\\ma\\core.py:3849\u001b[0m, in \u001b[0;36mMaskedArray.filled\u001b[1;34m(self, fill_value)\u001b[0m\n\u001b[0;32m   3847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n\u001b[0;32m   3848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3849\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3850\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3851\u001b[0m         np\u001b[38;5;241m.\u001b[39mcopyto(result, fill_value, where\u001b[38;5;241m=\u001b[39mm)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.14 GiB for an array with shape (6331638, 109) and data type float64"
     ]
    }
   ],
   "source": [
    "#starting with a simple imputer since it is computationally expensive\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Initialize the SimpleImputer\n",
    "simple_imputer = SimpleImputer(strategy=\"mean\")  # Use \"median\" or \"most_frequent\" if preferred\n",
    "\n",
    "# Apply imputation\n",
    "X_imputed = pd.DataFrame(simple_imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Check for missing values after imputation\n",
    "print(\"Remaining missing values per column:\\n\", X_imputed.isnull().sum())\n",
    "\n",
    "# Scale the imputed data\n",
    "scaler = RobustScaler()  # Switch to StandardScaler or MinMaxScaler if needed\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X_imputed.columns)\n",
    "\n",
    "# Print the first few rows of the processed dataset\n",
    "print(X_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting variance sum graph before PCA\n",
    "# Calculate variance for each feature in the original dataset\n",
    "feature_variance = X_scaled.var()  # Variance of each feature\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(feature_variance.cumsum(), marker='o', linestyle='--')\n",
    "plt.title('Cumulative Variance Sum of Features Before PCA')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cumulative Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA - Set the number of components you want\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of variance, adjust as necessary\n",
    "\n",
    "# Fit PCA on scaled data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create a DataFrame from the PCA components\n",
    "X_pca_df = pd.DataFrame(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Plot the variance explained by each principal component\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "             y=pca.explained_variance_ratio_, marker='o')\n",
    "plt.title('Explained Variance by Each Principal Component')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "             y=np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Save the PCA-transformed data to a CSV file\n",
    "X_pca_df.to_csv('pca_transformed_data.csv', index=False)\n",
    "\n",
    "print(\"PCA transformed data saved as 'pca_transformed_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
