{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enzo sent me the directly preprocessed file because I don't have enough storage right now\n",
    "#But you can just run the pipeline otherwise\n",
    "df = pd.read_csv('../../knnData/BA_US_knn_text.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>user_id</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>avg</th>\n",
       "      <th>user_state</th>\n",
       "      <th>beer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kupfer Kolsch</td>\n",
       "      <td>289320.0</td>\n",
       "      <td>Copper State Brewing Company</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>Kölsch</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.76</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Northwestern Alt</td>\n",
       "      <td>289321.0</td>\n",
       "      <td>Copper State Brewing Company</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>4.6</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.58</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Cent Wheat</td>\n",
       "      <td>289319.0</td>\n",
       "      <td>Copper State Brewing Company</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>Witbier</td>\n",
       "      <td>5.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beer_name   beer_id                  brewery_name  brewery_id  \\\n",
       "0     Kupfer Kolsch  289320.0  Copper State Brewing Company     49595.0   \n",
       "1  Northwestern Alt  289321.0  Copper State Brewing Company     49595.0   \n",
       "2    One Cent Wheat  289319.0  Copper State Brewing Company     49595.0   \n",
       "\n",
       "     style  abv       user_id  appearance  aroma  palate  taste  overall  \\\n",
       "0   Kölsch  4.4  n2185.211743        2.50   4.00    4.00   3.75     3.75   \n",
       "1  Altbier  4.6  n2185.211743        3.00   3.75    4.00   3.50     3.50   \n",
       "2  Witbier  5.4  n2185.211743        3.75   3.25    3.75   3.50     3.50   \n",
       "\n",
       "   rating text   avg      user_state beer_state  \n",
       "0    3.76  NaN  3.76  North Carolina  Wisconsin  \n",
       "1    3.58  NaN  3.58  North Carolina  Wisconsin  \n",
       "2    3.48  NaN  3.48  North Carolina  Wisconsin  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>user_id</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49595.0</td>\n",
       "      <td>Kölsch</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49595.0</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>4.6</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49595.0</td>\n",
       "      <td>Witbier</td>\n",
       "      <td>5.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brewery_id    style  abv       user_id  appearance  aroma  palate  taste  \\\n",
       "0     49595.0   Kölsch  4.4  n2185.211743        2.50   4.00    4.00   3.75   \n",
       "1     49595.0  Altbier  4.6  n2185.211743        3.00   3.75    4.00   3.50   \n",
       "2     49595.0  Witbier  5.4  n2185.211743        3.75   3.25    3.75   3.50   \n",
       "\n",
       "   overall  rating  \n",
       "0     3.75    3.76  \n",
       "1     3.50    3.58  \n",
       "2     3.50    3.48  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['beer_name', 'beer_id','brewery_name','avg','user_state', 'beer_state', 'text']\n",
    "\n",
    "# Drop the specified columns\n",
    "X = df.drop(columns=columns_to_drop)\n",
    "y = df['user_state']\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abv</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>style_Altbier</th>\n",
       "      <th>style_American Adjunct Lager</th>\n",
       "      <th>style_American Amber / Red Ale</th>\n",
       "      <th>...</th>\n",
       "      <th>style_Scottish Gruit / Ancient Herbed Ale</th>\n",
       "      <th>style_Smoked Beer</th>\n",
       "      <th>style_Tripel</th>\n",
       "      <th>style_Vienna Lager</th>\n",
       "      <th>style_Weizenbock</th>\n",
       "      <th>style_Wheatwine</th>\n",
       "      <th>style_Winter Warmer</th>\n",
       "      <th>style_Witbier</th>\n",
       "      <th>user_id_encoded</th>\n",
       "      <th>brewery_id_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.58</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abv  appearance  aroma  palate  taste  overall  rating  style_Altbier  \\\n",
       "0  4.4        2.50   4.00    4.00   3.75     3.75    3.76          False   \n",
       "1  4.6        3.00   3.75    4.00   3.50     3.50    3.58           True   \n",
       "2  5.4        3.75   3.25    3.75   3.50     3.50    3.48          False   \n",
       "\n",
       "   style_American Adjunct Lager  style_American Amber / Red Ale  ...  \\\n",
       "0                         False                           False  ...   \n",
       "1                         False                           False  ...   \n",
       "2                         False                           False  ...   \n",
       "\n",
       "   style_Scottish Gruit / Ancient Herbed Ale  style_Smoked Beer  style_Tripel  \\\n",
       "0                                      False              False         False   \n",
       "1                                      False              False         False   \n",
       "2                                      False              False         False   \n",
       "\n",
       "   style_Vienna Lager  style_Weizenbock  style_Wheatwine  style_Winter Warmer  \\\n",
       "0               False             False            False                False   \n",
       "1               False             False            False                False   \n",
       "2               False             False            False                False   \n",
       "\n",
       "   style_Witbier  user_id_encoded  brewery_id_encoded  \n",
       "0          False          0.00036            0.000001  \n",
       "1          False          0.00036            0.000001  \n",
       "2           True          0.00036            0.000001  \n",
       "\n",
       "[3 rows x 112 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#one hot encode beer style\n",
    "#frequency encode brewery_id and user_id\n",
    "\n",
    "X = pd.get_dummies(X, columns=['style'], prefix=['style'])\n",
    "user_frequency = X['user_id'].value_counts() / len(X)  # Frequency of each user_id\n",
    "\n",
    "# Map each user_id to its frequency\n",
    "X['user_id_encoded'] = X['user_id'].map(user_frequency)\n",
    "brewery_frequency = X['brewery_id'].value_counts() / len(X)  # Frequency of each brewery_id\n",
    "\n",
    "# Map each brewery_id to its frequency\n",
    "X['brewery_id_encoded'] = X['brewery_id'].map(brewery_frequency)\n",
    "X = X.drop(columns=['user_id', 'brewery_id'])\n",
    "\n",
    "#label encoding target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "X.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Assuming your DataFrame is named 'X' and the target variable is 'y' (already defined)\\n\\n# Initialize the RandomForestClassifier\\nrf = RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42)  # Limit the depth of each tree\\nrf.fit(X, y)\\n\\n# Fit the model on the data\\nrf.fit(X, y)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# Assuming your DataFrame is named 'X' and the target variable is 'y' (already defined)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42)  # Limit the depth of each tree\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Fit the model on the data\n",
    "rf.fit(X, y)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Get feature importances from the trained model\\nfeature_importances = rf.feature_importances_\\n\\nfeature_names = X.columns\\n\\nfeature_importance_df = pd.DataFrame({\\n    'Feature': feature_names,\\n    'Importance': feature_importances\\n})\\n\\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\\n\\n# Print the feature rankings\\n\\nfeature_importance_df.head(15)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Get feature importances from the trained model\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature rankings\n",
    "\n",
    "feature_importance_df.head(15)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Plot the feature importances\\nplt.figure(figsize=(12, 8))\\nplt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\\nplt.xlabel('Feature Importance')\\nplt.ylabel('Feature')\\nplt.title('Feature Importance Ranking')\\nplt.gca().invert_yaxis()\\nplt.show()\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance Ranking')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.28 GiB for an array with shape (6331638, 112) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Standardize the data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 3\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Perform PCA\u001b[39;00m\n\u001b[0;32m      6\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA()\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:999\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(X)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 999\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_ \u001b[38;5;241m=\u001b[39m \u001b[43m_incremental_mean_and_var\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_samples_seen_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;66;03m# for backward-compatibility, reduce n_samples_seen_ to an integer\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;66;03m# if the number of samples is the same for each feature (i.e. no\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# missing values)\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mptp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1155\u001b[0m, in \u001b[0;36m_incremental_mean_and_var\u001b[1;34m(X, last_mean, last_variance, last_sample_count, sample_weight)\u001b[0m\n\u001b[0;32m   1151\u001b[0m     new_unnormalized_variance \u001b[38;5;241m=\u001b[39m _safe_accumulator_op(\n\u001b[0;32m   1152\u001b[0m         np\u001b[38;5;241m.\u001b[39mmatmul, sample_weight, np\u001b[38;5;241m.\u001b[39mwhere(X_nan_mask, \u001b[38;5;241m0\u001b[39m, temp)\n\u001b[0;32m   1153\u001b[0m     )\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1155\u001b[0m     correction \u001b[38;5;241m=\u001b[39m \u001b[43m_safe_accumulator_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43msum_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1156\u001b[0m     temp \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   1157\u001b[0m     new_unnormalized_variance \u001b[38;5;241m=\u001b[39m _safe_accumulator_op(sum_op, temp, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1053\u001b[0m, in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1051\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1053\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:722\u001b[0m, in \u001b[0;36mnansum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_nansum_dispatcher)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnansum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m    625\u001b[0m            initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m    626\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    Return the sum of array elements over a given axis treating Not a\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;124;03m    Numbers (NaNs) as zero.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    720\u001b[0m \n\u001b[0;32m    721\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 722\u001b[0m     a, mask \u001b[38;5;241m=\u001b[39m \u001b[43m_replace_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m    724\u001b[0m                   initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:107\u001b[0m, in \u001b[0;36m_replace_nan\u001b[1;34m(a, val)\u001b[0m\n\u001b[0;32m    104\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     np\u001b[38;5;241m.\u001b[39mcopyto(a, val, where\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a, mask\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.28 GiB for an array with shape (6331638, 112) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Get the explained variance ratio (importance of each component)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Get the principal components (loading vectors)\n",
    "components = pca.components_\n",
    "\n",
    "# Convert the components to a DataFrame to better visualize feature importance\n",
    "feature_importance_df = pd.DataFrame(components, columns=X.columns, index=[f'PC{i+1}' for i in range(components.shape[0])])\n",
    "\n",
    "# To get the absolute value of the feature importance\n",
    "feature_importance_abs = feature_importance_df.abs()\n",
    "\n",
    "# Sum the absolute values of the components for each feature (overall importance)\n",
    "feature_importance = feature_importance_abs.sum(axis=0)\n",
    "\n",
    "# Sort the features by importance\n",
    "feature_importance_sorted = feature_importance.sort_values(ascending=False)\n",
    "\n",
    "# Display the sorted feature importance\n",
    "print(\"Feature Importance (sorted):\")\n",
    "print(feature_importance_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the variance sum graph (cumulative variance plot)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(explained_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "plt.title('Variance Sum (Cumulative Explained Variance) by Principal Components')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
