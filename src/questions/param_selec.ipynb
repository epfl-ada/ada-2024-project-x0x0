{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this file will make a csv file called pca_transformed_data.csv which will contain the new features to use for K means clustering (which explain 95% of the variance- but we can change this accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enzo sent me the directly preprocessed file because I don't have enough storage right now\n",
    "#But you can just run the pipeline otherwise\n",
    "df = pd.read_csv('../../knnData/BA_US_knn_text.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6331638, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>user_id</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>avg</th>\n",
       "      <th>user_state</th>\n",
       "      <th>beer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kupfer Kolsch</td>\n",
       "      <td>289320.0</td>\n",
       "      <td>Copper State Brewing Company</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>Kölsch</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.76</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Northwestern Alt</td>\n",
       "      <td>289321.0</td>\n",
       "      <td>Copper State Brewing Company</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>4.6</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.58</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Cent Wheat</td>\n",
       "      <td>289319.0</td>\n",
       "      <td>Copper State Brewing Company</td>\n",
       "      <td>49595.0</td>\n",
       "      <td>Witbier</td>\n",
       "      <td>5.4</td>\n",
       "      <td>n2185.211743</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Wisconsin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beer_name   beer_id                  brewery_name  brewery_id  \\\n",
       "0     Kupfer Kolsch  289320.0  Copper State Brewing Company     49595.0   \n",
       "1  Northwestern Alt  289321.0  Copper State Brewing Company     49595.0   \n",
       "2    One Cent Wheat  289319.0  Copper State Brewing Company     49595.0   \n",
       "\n",
       "     style  abv       user_id  appearance  aroma  palate  taste  overall  \\\n",
       "0   Kölsch  4.4  n2185.211743        2.50   4.00    4.00   3.75     3.75   \n",
       "1  Altbier  4.6  n2185.211743        3.00   3.75    4.00   3.50     3.50   \n",
       "2  Witbier  5.4  n2185.211743        3.75   3.25    3.75   3.50     3.50   \n",
       "\n",
       "   rating text   avg      user_state beer_state  \n",
       "0    3.76  NaN  3.76  North Carolina  Wisconsin  \n",
       "1    3.58  NaN  3.58  North Carolina  Wisconsin  \n",
       "2    3.48  NaN  3.48  North Carolina  Wisconsin  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1829363, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>abv</th>\n",
       "      <th>user_id</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>939.0</td>\n",
       "      <td>Munich Helles Lager</td>\n",
       "      <td>5.2</td>\n",
       "      <td>scaliasux.16164</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>939.0</td>\n",
       "      <td>Munich Helles Lager</td>\n",
       "      <td>5.2</td>\n",
       "      <td>jwc215.53566</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>939.0</td>\n",
       "      <td>Munich Helles Lager</td>\n",
       "      <td>5.2</td>\n",
       "      <td>cagocubs.283312</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brewery_id                style  abv          user_id  appearance  aroma  \\\n",
       "50       939.0  Munich Helles Lager  5.2  scaliasux.16164        4.00   4.00   \n",
       "53       939.0  Munich Helles Lager  5.2     jwc215.53566        3.25   3.25   \n",
       "62       939.0  Munich Helles Lager  5.2  cagocubs.283312        2.50   3.00   \n",
       "\n",
       "    palate  taste  overall  rating  \n",
       "50     3.5   3.50     4.00    3.75  \n",
       "53     3.5   3.25     3.25    3.28  \n",
       "62     3.5   3.50     3.50    3.32  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['beer_name', 'beer_id','brewery_name','avg','user_state', 'beer_state', 'text']\n",
    "\n",
    "# Drop the specified columns\n",
    "X_drop_na = df.dropna()\n",
    "X_drop = X_drop_na.drop(columns=columns_to_drop)\n",
    "y = df['user_state']\n",
    "\n",
    "print(X_drop.shape)\n",
    "X_drop.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abv</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>style_Altbier</th>\n",
       "      <th>style_American Adjunct Lager</th>\n",
       "      <th>style_American Amber / Red Ale</th>\n",
       "      <th>...</th>\n",
       "      <th>style_Scottish Gruit / Ancient Herbed Ale</th>\n",
       "      <th>style_Smoked Beer</th>\n",
       "      <th>style_Tripel</th>\n",
       "      <th>style_Vienna Lager</th>\n",
       "      <th>style_Weizenbock</th>\n",
       "      <th>style_Wheatwine</th>\n",
       "      <th>style_Winter Warmer</th>\n",
       "      <th>style_Witbier</th>\n",
       "      <th>user_id_encoded</th>\n",
       "      <th>brewery_id_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.58</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abv  appearance  aroma  palate  taste  overall  rating  style_Altbier  \\\n",
       "0  4.4        2.50   4.00    4.00   3.75     3.75    3.76          False   \n",
       "1  4.6        3.00   3.75    4.00   3.50     3.50    3.58           True   \n",
       "2  5.4        3.75   3.25    3.75   3.50     3.50    3.48          False   \n",
       "\n",
       "   style_American Adjunct Lager  style_American Amber / Red Ale  ...  \\\n",
       "0                         False                           False  ...   \n",
       "1                         False                           False  ...   \n",
       "2                         False                           False  ...   \n",
       "\n",
       "   style_Scottish Gruit / Ancient Herbed Ale  style_Smoked Beer  style_Tripel  \\\n",
       "0                                      False              False         False   \n",
       "1                                      False              False         False   \n",
       "2                                      False              False         False   \n",
       "\n",
       "   style_Vienna Lager  style_Weizenbock  style_Wheatwine  style_Winter Warmer  \\\n",
       "0               False             False            False                False   \n",
       "1               False             False            False                False   \n",
       "2               False             False            False                False   \n",
       "\n",
       "   style_Witbier  user_id_encoded  brewery_id_encoded  \n",
       "0          False          0.00036            0.000001  \n",
       "1          False          0.00036            0.000001  \n",
       "2           True          0.00036            0.000001  \n",
       "\n",
       "[3 rows x 112 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_drop\n",
    "#one hot encode beer style\n",
    "#frequency encode brewery_id and user_id\n",
    "\n",
    "X = pd.get_dummies(X, columns=['style'], prefix=['style'])\n",
    "user_frequency = X['user_id'].value_counts() / len(X)  # Frequency of each user_id\n",
    "\n",
    "# Map each user_id to its frequency\n",
    "X['user_id_encoded'] = X['user_id'].map(user_frequency)\n",
    "brewery_frequency = X['brewery_id'].value_counts() / len(X)  # Frequency of each brewery_id\n",
    "\n",
    "# Map each brewery_id to its frequency\n",
    "X['brewery_id_encoded'] = X['brewery_id'].map(brewery_frequency)\n",
    "X = X.drop(columns=['user_id', 'brewery_id'])\n",
    "\n",
    "#label encoding target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "X.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Assuming your DataFrame is named 'X' and the target variable is 'y' (already defined)\\n\\n# Initialize the RandomForestClassifier\\nrf = RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42)  # Limit the depth of each tree\\nrf.fit(X, y)\\n\\n# Fit the model on the data\\nrf.fit(X, y)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# Assuming your DataFrame is named 'X' and the target variable is 'y' (already defined)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42)  # Limit the depth of each tree\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Fit the model on the data\n",
    "rf.fit(X, y)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Get feature importances from the trained model\\nfeature_importances = rf.feature_importances_\\n\\nfeature_names = X.columns\\n\\nfeature_importance_df = pd.DataFrame({\\n    'Feature': feature_names,\\n    'Importance': feature_importances\\n})\\n\\nfeature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\\n\\n# Print the feature rankings\\n\\nfeature_importance_df.head(15)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Get feature importances from the trained model\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature rankings\n",
    "\n",
    "feature_importance_df.head(15)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Plot the feature importances\\nplt.figure(figsize=(12, 8))\\nplt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\\nplt.xlabel('Feature Importance')\\nplt.ylabel('Feature')\\nplt.title('Feature Importance Ranking')\\nplt.gca().invert_yaxis()\\nplt.show(\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance Ranking')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show('''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#covariance matrix to remove highly correlated variables first\\n#PCA to reduce feature dimension\\n\\ncorr_matrix = X.corr()  # Compute correlation matrix for your features\\n\\nplt.figure(figsize=(10, 8))\\nsns.heatmap(corr_matrix, annot=True, cmap=\\'coolwarm\\', fmt=\".2f\")\\nplt.title(\"Feature Correlation Matrix\")\\nplt.show()'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#covariance matrix to remove highly correlated variables first\n",
    "#PCA to reduce feature dimension\n",
    "\n",
    "corr_matrix = X.corr()  # Compute correlation matrix for your features\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'threshold = 0.8\\n# Extract the upper triangle of the correlation matrix (excluding diagonal)\\nupper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\\n\\n# Find all feature pairs with correlation above the threshold\\nhigh_corr_pairs = []\\nfor i in range(len(upper_triangle.columns)):\\n    for j in range(i + 1, len(upper_triangle.columns)):\\n        if abs(upper_triangle.iloc[i, j]) > threshold:  # Check threshold\\n            high_corr_pairs.append(\\n                (upper_triangle.index[i], upper_triangle.columns[j], upper_triangle.iloc[i, j])\\n            )\\n\\n# Create a DataFrame to display the results\\nhigh_corr_df = pd.DataFrame(high_corr_pairs, columns=[\"Feature1\", \"Feature2\", \"Correlation\"])\\nprint(\"Features with more than a 0.8 correlation value\")\\nprint(high_corr_df)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''threshold = 0.8\n",
    "# Extract the upper triangle of the correlation matrix (excluding diagonal)\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find all feature pairs with correlation above the threshold\n",
    "high_corr_pairs = []\n",
    "for i in range(len(upper_triangle.columns)):\n",
    "    for j in range(i + 1, len(upper_triangle.columns)):\n",
    "        if abs(upper_triangle.iloc[i, j]) > threshold:  # Check threshold\n",
    "            high_corr_pairs.append(\n",
    "                (upper_triangle.index[i], upper_triangle.columns[j], upper_triangle.iloc[i, j])\n",
    "            )\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "high_corr_df = pd.DataFrame(high_corr_pairs, columns=[\"Feature1\", \"Feature2\", \"Correlation\"])\n",
    "print(\"Features with more than a 0.8 correlation value\")\n",
    "print(high_corr_df)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually removing features: Remove aroma (since rating is central and likely more informative).\n",
    "Remove palate (same reasoning).\n",
    "Remove overall (keep taste or vice versa). (for now lets keep overall and remove taste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_to_remove = ['aroma', 'palate', 'overall']\n",
    "X = X.drop(columns=features_to_remove)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.86 GiB for an array with shape (103, 6331638) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Scale the imputed data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m scaler \u001b[38;5;241m=\u001b[39m RobustScaler()  \u001b[38;5;66;03m# Switch to StandardScaler or MinMaxScaler if needed\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Print the first few rows of the processed dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_scaled\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1658\u001b[0m, in \u001b[0;36mRobustScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1645\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Center and scale the data.\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m \n\u001b[0;32m   1647\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;124;03m    Transformed array.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1657\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1658\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1660\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_scaling:\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[1;32m-> 1074\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmay_share_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_orig\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1075\u001b[0m             array \u001b[38;5;241m=\u001b[39m _asarray_with_order(\n\u001b[0;32m   1076\u001b[0m                 array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m   1077\u001b[0m             )\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1079\u001b[0m         \u001b[38;5;66;03m# always make a copy for non-numpy arrays\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\pandas\\core\\generic.py:2152\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\n\u001b[0;32m   2150\u001b[0m     \u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2152\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\n\u001b[0;32m   2153\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2155\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2156\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2157\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2158\u001b[0m     ):\n\u001b[0;32m   2159\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\pandas\\core\\frame.py:1127\u001b[0m, in \u001b[0;36mDataFrame._values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1125\u001b[0m blocks \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m)\n\u001b[0;32m   1129\u001b[0m arr \u001b[38;5;241m=\u001b[39m blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m# non-2D ExtensionArray\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\pandas\\core\\frame.py:12664\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12590\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  12591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  12592\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  12593\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  12594\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12662\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  12663\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1735\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m   1734\u001b[0m     rl \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mmgr_locs\n\u001b[1;32m-> 1735\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1736\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1737\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\iaran\\miniconda3\\envs\\ada\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:2588\u001b[0m, in \u001b[0;36mNumpyBlock.get_values\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: DtypeObj \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m _dtype_obj:\n\u001b[1;32m-> 2588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(_dtype_obj)\n\u001b[0;32m   2589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.86 GiB for an array with shape (103, 6331638) and data type object"
     ]
    }
   ],
   "source": [
    "#starting with a simple imputer since it is computationally expensive\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "# Scale the imputed data\n",
    "scaler = RobustScaler()  # Switch to StandardScaler or MinMaxScaler if needed\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Print the first few rows of the processed dataset\n",
    "X_scaled = X_scaled.dropna()\n",
    "print(X_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting variance sum graph before PCA\n",
    "# Calculate variance for each feature in the original dataset\n",
    "feature_variance = X_scaled.var()  # Variance of each feature\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(feature_variance.cumsum(), marker='o', linestyle='--')\n",
    "plt.title('Cumulative Variance Sum of Features Before PCA')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cumulative Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA - Set the number of components you want\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of variance, adjust as necessary\n",
    "\n",
    "# Fit PCA on scaled data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create a DataFrame from the PCA components\n",
    "X_pca_df = pd.DataFrame(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Plot the variance explained by each principal component\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "             y=pca.explained_variance_ratio_, marker='o')\n",
    "plt.title('Explained Variance by Each Principal Component')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "             y=np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Save the PCA-transformed data to a CSV file\n",
    "X_pca_df.to_csv('pca_transformed_data.csv', index=False)\n",
    "\n",
    "print(\"PCA transformed data saved as 'pca_transformed_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the DataFrame: {X_pca_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
